{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b93268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1cb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9867f709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train:(60000, 28, 28),x_test:(10000, 28, 28),y_train:(60000,),y_test:(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train:{x_train.shape},x_test:{x_test.shape},y_train:{y_train.shape},y_test:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5758bd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print 4 images in a row\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    plt.imshow(x_train[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecebbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Flatten,Dense,MaxPooling2D\n",
    "\n",
    "# reshaping input values (28,28) is for image height and width,1 is for gray scale images and \n",
    "# -1 is for python to decide the batch size here for training data it will be 60000\n",
    "# it is necessary for a CNN to have a 4D vector as input\n",
    "x_train=x_train.reshape(-1,28,28,1).astype(\"float32\")/255\n",
    "x_test=x_test.reshape(-1,28,28,1).astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5c2a340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train:(60000, 28, 28, 1),x_test:(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of x_train:{x_train.shape},x_test:{x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4d42d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model=Sequential([\n",
    "    Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(10,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d3cdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9070 - loss: 0.3135 - val_accuracy: 0.9805 - val_loss: 0.0633\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 0.0529 - val_accuracy: 0.9839 - val_loss: 0.0477\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9912 - loss: 0.0306 - val_accuracy: 0.9839 - val_loss: 0.0468\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0191 - val_accuracy: 0.9862 - val_loss: 0.0430\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0134 - val_accuracy: 0.9864 - val_loss: 0.0461\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0085 - val_accuracy: 0.9849 - val_loss: 0.0512\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0070 - val_accuracy: 0.9872 - val_loss: 0.0487\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.9877 - val_loss: 0.0474\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9857 - val_loss: 0.0614\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9981 - loss: 0.0060 - val_accuracy: 0.9894 - val_loss: 0.0481\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9872 - val_loss: 0.0558\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9991 - loss: 0.0023 - val_accuracy: 0.9872 - val_loss: 0.0635\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9856 - val_loss: 0.0691\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9873 - val_loss: 0.0621\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.9860 - val_loss: 0.0704\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0019 - val_accuracy: 0.9863 - val_loss: 0.0772\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.9894 - val_loss: 0.0654\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.9878 - val_loss: 0.0705\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0026 - val_accuracy: 0.9883 - val_loss: 0.0736\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9855 - val_loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# train and save model\n",
    "model.fit(x_train,y_train,epochs=20,validation_data=(x_test,y_test))\n",
    "model.save(\"digits.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122f318f",
   "metadata": {},
   "source": [
    "# Sample Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "423d47c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Predicted digit: 2\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load saved model\n",
    "model = load_model(\"digits.h5\")\n",
    "# Load and convert to grayscale\n",
    "img = Image.open(\"7.png\").convert(\"L\")  # 'L' = grayscale\n",
    "\n",
    "# Resize to 28x28 if not already\n",
    "img = img.resize((28, 28))\n",
    "\n",
    "# Convert to NumPy array and normalize\n",
    "img_array = np.array(img).astype(\"float32\") / 255.0\n",
    "\n",
    "# Invert colors if background is black (MNIST digits are white on black)\n",
    "img_array = 1 - img_array\n",
    "\n",
    "# Reshape to (1, 28, 28, 1) for prediction\n",
    "img_array = img_array.reshape(1, 28, 28, 1)\n",
    "\n",
    "pred = model.predict(img_array)\n",
    "predicted_class = np.argmax(pred)\n",
    "\n",
    "print(\"Predicted digit:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f129aa0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
